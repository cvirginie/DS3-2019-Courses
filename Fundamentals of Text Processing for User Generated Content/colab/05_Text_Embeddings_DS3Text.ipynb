{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Text_Embeddings_DS3Text.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steve-wilson/ds32019/blob/master/05_Text_Embeddings_DS3Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APfI_c8B40Vn",
        "colab_type": "text"
      },
      "source": [
        "#Fundamentals of Text Analysis for User Generated Content @ [DS3](https://www.ds3-datascience-polytechnique.fr/)\n",
        "\n",
        "# Part 5: Text Embeddings\n",
        "\n",
        "[<- Previous: Content Analysis](https://colab.research.google.com/drive/1CgXCh1-qxx1FWgSdCuXEKx-bWfAilOnQ)\n",
        "\n",
        "[-> Next: Machine Learning](https://colab.research.google.com/drive/1PLEJxfbgUNVQytJhG8HEyAVb8kE_eHwg)\n",
        "\n",
        "Dates: June 27-28, 2019\n",
        "\n",
        "Facilitator: [Steve Wilson](https://steverw.com)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdTajgZhkGWX",
        "colab_type": "text"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "- **Run \"Setup\" below first.**\n",
        "\n",
        "    - This will load libraries and download some resources that we'll use throughout the tutorial.\n",
        "\n",
        "    - You will see a message reading \"Done with setup!\" when this process completes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKVEnPi34qj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Setup (click the \"run\" button to the left) {display-mode: \"form\"}\n",
        "\n",
        "## Setup ##\n",
        "\n",
        "# imports\n",
        "\n",
        "# built-in Python libraries\n",
        "# -------------------------\n",
        "\n",
        "# for defaultdict data structure\n",
        "import collections\n",
        "# for reading csv files\n",
        "import csv\n",
        "# operating system functions\n",
        "import os\n",
        "\n",
        "# 3rd party libraries\n",
        "# -------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "! pip install --upgrade gensim\n",
        "import gensim\n",
        "import gensim.test.utils\n",
        "import gensim.scripts.glove2word2vec\n",
        "import gensim.models.fasttext\n",
        "\n",
        "import scipy.spatial.distance\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "! pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "if not os.path.exists(\"glove.twitter.27B.zip\"):\n",
        "    !wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "else:\n",
        "    print(\"GloVe already downloaded.\")\n",
        "if not os.path.exists(\"glove.twitter.27B.50d.txt\"):\n",
        "    !unzip glove.twitter.27B.zip\n",
        "else:\n",
        "    print(\"GloVe already extracted.\")\n",
        "if not os.path.exists(\"questions-words.txt\"):\n",
        "    !wget http://download.tensorflow.org/data/questions-words.txt\n",
        "else:\n",
        "    print(\"Word analogies data already loaded.\")\n",
        "if not os.path.exists(\"crawl-300d-2M-subword.zip\"):\n",
        "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
        "else:\n",
        "    print(\"Fasttext embeddings already downloaded\")\n",
        "if not os.path.exists(\"crawl-300d-2M-subword.vec\"):\n",
        "    print(\"Extracting Fasttext embeddings. This may take several minutes...\")\n",
        "    !unzip crawl-300d-2M-subword.zip\n",
        "else:\n",
        "    print(\"Fasttext already extracted.\")\n",
        "if not os.path.exists(\"Stsbenchmark.tar.gz\"):\n",
        "    !wget http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
        "    !tar -xzf Stsbenchmark.tar.gz\n",
        "print()\n",
        "print(\"Done with setup!\")\n",
        "print(\"If you'd like, you can click the (X) button to the left to clear this output.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah3YPx-h7Rjt",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## A - Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc9vfbk_7UXY",
        "colab_type": "text"
      },
      "source": [
        "### Using gensim for word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKRZDcr0mB6G",
        "colab_type": "text"
      },
      "source": [
        "- Gensim is back: this time we'll use it to experiment with word embeddings.\n",
        "- We can use it to load an embeddings matrix in several formats.\n",
        "    - Since we've been working with some social media data, let's load the GloVe Twitter embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vIv8CnH7agl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load 100-dimensional vectors\n",
        "glove_file_path = \"glove.twitter.27B.100d.txt\"\n",
        "# First convert to word2vec format (what gensim expects)\n",
        "tmp_file_path = gensim.test.utils.get_tmpfile(\"word2vec_twitter_100d.txt\")\n",
        "_ = gensim.scripts.glove2word2vec.glove2word2vec(glove_file_path, tmp_file_path)\n",
        "\n",
        "# Now load with gensim (may take several minutes)\n",
        "print(\"Loading GloVe...\")\n",
        "glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file_path)\n",
        "print(\"GloVe was loaded into memory.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR4R-6qmrgXK",
        "colab_type": "text"
      },
      "source": [
        "- **Now, what can we do with these embeddings?**\n",
        "- Find the most similar words to a query:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d20vsWL6rTxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove.most_similar(\"france\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEQn5rTzrnun",
        "colab_type": "text"
      },
      "source": [
        "- Measure similarity between any pair of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXPm1rdcrwqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs = [ ('data','pastry') , ('beautiful','lovely'), ('hot','cold'), \\\n",
        "          ('a person walked their dog','a dog walked with a person') , \\\n",
        "          ('the school was prestigious','the university was highly ranked')]\n",
        "\n",
        "for pair in pairs:\n",
        "    sim = glove.n_similarity(pair[0].split(),pair[1].split())\n",
        "    print(pair,\":\",sim)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3xEW7mwnUN",
        "colab_type": "text"
      },
      "source": [
        "- Or just get the vector representation for a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GglQMqgIwukb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector = glove['summer']\n",
        "print(vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkAh9Rta7bQa",
        "colab_type": "text"
      },
      "source": [
        "### Word embedding geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jCqP5XoxQWV",
        "colab_type": "text"
      },
      "source": [
        "- The classic example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgNhMhKe7fr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mystery_word_vec = glove['king'] - glove['man'] + glove['woman']\n",
        "glove.similar_by_vector(mystery_word_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKujVo2V8Lvs",
        "colab_type": "text"
      },
      "source": [
        "### Putting it together: word analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-NLjfd81Kyd",
        "colab_type": "text"
      },
      "source": [
        "- In the not-too-distance past, these types of questions appeared on American college entrance examinations:\n",
        "    - e.g., \"man:king::woman:?\"\n",
        "        - answer: queen\n",
        "- Around 2013, when word vectors were becoming extremely popular, this task was studied within the NLP community, and along with it came some standard datasets.\n",
        "    Let's load one of them here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cofHFFz01KTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogies = collections.defaultdict(list)\n",
        "category = \"\"\n",
        "with open(\"questions-words.txt\",'r') as analogy_questions:\n",
        "    for aq in analogy_questions:\n",
        "        if aq.startswith(\":\"):\n",
        "            category = aq.split(\":\")[1].strip()\n",
        "        else:\n",
        "            a,b,c,d = aq.split()\n",
        "            analogies[category].append([a,b,c,d])\n",
        "            \n",
        "print(\"Loaded analogies with\",len(analogies),\"categories.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drLyYe0cyXur",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 6**: Word analogies\n",
        "- Using the GloVe embeddings that we loaded before, write a function to complete word analogies.\n",
        "    - return a list of the top `top_n` guesses, in order from most likely to least likely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty58G36u8Qlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# solve an analogy a is to b as c is to ?\n",
        "def guess_analogy(a,b,c,vectors,top_n=5):\n",
        "    \n",
        "# ------------- Exercise 6 -------------- #\n",
        "\n",
        "\n",
        "    return []\n",
        "# ---------------- End ------------------ #\n",
        "    \n",
        "\n",
        "# quick test\n",
        "a,b,c,d = \"man\",\"king\",\"woman\",\"queen\"\n",
        "guesses = guess_analogy(a,b,c,glove)\n",
        "if d in guesses:\n",
        "    print(\"queen was in the top n guesses!\")\n",
        "else:\n",
        "    print(\"queen was NOT in the top n guesses...\")\n",
        "    print(\"guesses were:\",guesses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEBf9kApyLCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Sample Solution (double-click to view) {display-mode: \"form\"}\n",
        "\n",
        "def guess_analogy(a,b,c,vectors,top_n=5):\n",
        "    \n",
        "# ------------- Exercise 6 -------------- #\n",
        "\n",
        "    inputs = set([a,b,c])\n",
        "    guess_vector = vectors[b] - vectors[a] + vectors[c]\n",
        "    guesses = glove.similar_by_vector(guess_vector)\n",
        "    return [item[0] for item in guesses if item[0] not in inputs][:top_n]\n",
        "\n",
        "# ---------------- End ------------------ #\n",
        "\n",
        "\n",
        "# quick test\n",
        "a,b,c,d = \"man\",\"king\",\"woman\",\"queen\"\n",
        "guesses = guess_analogy(a,b,c,glove)\n",
        "if d in guesses:\n",
        "    print(\"queen was in the top n guesses!\")\n",
        "else:\n",
        "    print(\"queen was NOT in the top n guesses...\")\n",
        "    print(\"guesses were:\",guesses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdJIVzb6ygH",
        "colab_type": "text"
      },
      "source": [
        "- When you are ready, run your function on some more of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldXrUbvN6wFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluation\n",
        "\n",
        "# just check 100 per category, otherwise you will have to wait a while\n",
        "max_per_category = 100\n",
        "correct = collections.defaultdict(int)\n",
        "top_5_correct = collections.defaultdict(int)\n",
        "total = collections.defaultdict(int)\n",
        "for category, analogy_questions in analogies.items():\n",
        "    print(\"evaluating\",category)\n",
        "    for aq in analogy_questions[:max_per_category]:\n",
        "        a,b,c,d = aq\n",
        "        if all([item in glove for item in [a,b,c,d]]):\n",
        "            guesses = guess_analogy(a,b,c,glove)\n",
        "            total[category] += 1\n",
        "            if d in guesses:\n",
        "                top_5_correct[category] += 1\n",
        "                if d == guesses[0]:\n",
        "                    correct[category] += 1\n",
        "                \n",
        "global_correct = 0\n",
        "global_top_5_correct = 0\n",
        "global_total = 0\n",
        "print()\n",
        "print(\"Category-level results\")\n",
        "for category in analogies:\n",
        "    if total[category]:\n",
        "        print(category)\n",
        "        print(\"\\t\",\"top-1 score:\",float(correct[category])/total[category])\n",
        "        print(\"\\t\",\"top-5 score:\",float(top_5_correct[category])/total[category])\n",
        "        global_correct += correct[category]\n",
        "        global_top_5_correct += top_5_correct[category]\n",
        "        global_total += total[category]\n",
        "print(\"Overall results\")\n",
        "print(\"\\t\",\"top-1 score:\",float(global_correct)/global_total)\n",
        "print(\"\\t\",\"top-5 score:\",float(global_top_5_correct)/global_total)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV8__Z_tBHKy",
        "colab_type": "text"
      },
      "source": [
        "- Did you get better results than the sample solution?\n",
        "    - It achieved, overall:\n",
        "        - top-1: 0.46875\n",
        "        - top-5: 0.640625\n",
        "- What could you do to improve the results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_mAiar69XVS",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## B - Sub-words and Compositionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc6DBleGGFYk",
        "colab_type": "text"
      },
      "source": [
        "- You may have noticed that our word embeddings don't always work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32cQtzvXCIN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# note that the current version of GloVe Twitter is about 5 years old now\n",
        "try:\n",
        "    print(glove['adulting'])\n",
        "except Exception as e:\n",
        "    print(\"Error:\",e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Okogf3IxO8",
        "colab_type": "text"
      },
      "source": [
        "- How could we address this?\n",
        "- We could:\n",
        "    - skip words for which we do not have embeddings\n",
        "    - use the same \"out of vocabulary\" (OOV) vector to represent each unknown word.\n",
        "    - re-train our word embeddings every...\n",
        "        - year? month? day?\n",
        "    - change the unit of semantics from *words* to *something else*.\n",
        "        - What else might we choose?\n",
        "            - Some proposals include subwords, word pieces, and characters.\n",
        "- Let's consider the last approach, first by looking at subword embeddings with fasttext:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ExQY49CBvJ",
        "colab_type": "text"
      },
      "source": [
        "### Sub-words embeddings with FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5OrZZOvKDX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can also load these using gensim\n",
        "# this will also take several minutes to load into memory\n",
        "emb_path = \"crawl-300d-2M-subword.bin\"\n",
        "fasttext_model = fasttext.load_model(emb_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2UI57GtMC4J",
        "colab_type": "text"
      },
      "source": [
        "- We can do the same kinds of things that we did before with GloVe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tllsXn1XMGhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"First 50 dimensions of vector for computer:\")\n",
        "print(fasttext_model['computer'][:50])\n",
        "\n",
        "print(\"Similarity between 'forest' and 'trees':\")\n",
        "print(1- scipy.spatial.distance.cosine(fasttext_model['forest'], fasttext_model['trees']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd4YHEacRB6Y",
        "colab_type": "text"
      },
      "source": [
        "- In addition, we can use subword information to reason about unknown words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjH7U3gARHJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"First 50 dimensions of vector for adulting:\")\n",
        "print(fasttext_model['adulting'][:50])\n",
        "print()\n",
        "# just to prove that totally new words are handled\n",
        "print(\"First 50 dimensions of vector for howhoozaling:\")\n",
        "print(fasttext_model['howhoozaling'][:50])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFyVLQ8CJM7",
        "colab_type": "text"
      },
      "source": [
        "### Semantic compositions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmBWd9yXL3xq",
        "colab_type": "text"
      },
      "source": [
        "- Simply averaging word embeddings (mean pooling) turns out to be a strong baseline for short text representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljAMMzl2CO1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent1 = \"The airplane flew over the fields\"\n",
        "sent2 = \"A train crossed the river\"\n",
        "\n",
        "sent1_emb = np.mean([fasttext_model[w.lower()] for w in sent1.split()],axis=0)\n",
        "sent2_emb = np.mean([fasttext_model[w.lower()] for w in sent2.split()],axis=0)\n",
        "\n",
        "print(\"Similarity:\",1- scipy.spatial.distance.cosine(sent1_emb,sent2_emb))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOkb06JGCRc9",
        "colab_type": "text"
      },
      "source": [
        "### Putting it together: short text similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjqKfik8rfbE",
        "colab_type": "text"
      },
      "source": [
        "- SemEval is a yearly competition to solve a range of semantic NLP tasks.\n",
        "- A common SemEval task is \"semantic text similarity\".\n",
        "    - The goal is to build a model that can produce similarity scores for pairs of texts that are highly correlated with human judgements of similarity.\n",
        "    - Let's load some data for this task:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHwjDInJsLtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sts_data = []\n",
        "fnames = ['section1','section2','section3','docid','score','doc1','doc2']\n",
        "with open(\"stsbenchmark/sts-test.csv\",'r') as infile:\n",
        "    reader = csv.DictReader(infile, fieldnames=fnames,dialect=csv.excel_tab)\n",
        "    for row in reader:\n",
        "        test_sts_data.append(row)\n",
        "print(\"Loaded\",len(test_sts_data),\"test pairs.\")\n",
        "print(\"Example:\",test_sts_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO3Ui7vLsMKa",
        "colab_type": "text"
      },
      "source": [
        "- Now, let's build a simple system to get some reasonable results on this task.\n",
        "    - hint: stopword removal should be helpful here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7YJTljkCZyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_text_sim_score(text1,text2,word_embeddings):\n",
        "\n",
        "# ------------- Exercise 3 -------------- #\n",
        "\n",
        "\n",
        "\n",
        "# ---------------- End ------------------ #\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1y4PvfMyMMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Sample Solution (double-click to view) {display-mode: \"form\"}\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def get_text_sim_score(text1,text2,word_embeddings):\n",
        "\n",
        "# ------------- Exercise 3 -------------- #\n",
        "\n",
        "    vec1 = np.mean([word_embeddings[w] for w in text1.split() if w.lower() not in stopwords],axis=0)\n",
        "    vec2 = np.mean([word_embeddings[w] for w in text2.split() if w.lower() not in stopwords],axis=0)\n",
        "    score = 1 - scipy.spatial.distance.cosine(vec1,vec2)\n",
        "\n",
        "# ---------------- End ------------------ #\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p31HO9h5tYs5",
        "colab_type": "text"
      },
      "source": [
        "- Let's evaluate the performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CPvttc_tcoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "golds, preds = [],[]\n",
        "for test_data in test_sts_data:\n",
        "    text1 = test_data['doc1']\n",
        "    text2 = test_data['doc2']\n",
        "    if text1 and text2:\n",
        "        gold = float(test_data['score'])\n",
        "        pred = get_text_sim_score(text1,text2,fasttext_model)\n",
        "        golds.append(gold)\n",
        "        preds.append(pred)\n",
        "\n",
        "print(\"Some examples of pairs and their human annotated scores:\")\n",
        "for item in test_sts_data[:5]:\n",
        "    print(item['score'],item['doc1'],item['doc2'])\n",
        "print(\"Correct labels:\",golds[:5])\n",
        "print(\"Predictions:\",preds[:5])\n",
        "print(\"Correlation Score (rho, p-value):\",scipy.stats.pearsonr(golds,preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXc7bqB5SRLY",
        "colab_type": "text"
      },
      "source": [
        "- That is a good start! \n",
        "- It's definitely possible to do better with different compisition functions/networks, or even this same approach with different embeddings.\n",
        "    - See some of the state-of-the-art results here: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHJks7U5ybrD",
        "colab_type": "text"
      },
      "source": [
        "- [-> Next: Machine Learning](https://colab.research.google.com/drive/1PLEJxfbgUNVQytJhG8HEyAVb8kE_eHwg)"
      ]
    }
  ]
}
