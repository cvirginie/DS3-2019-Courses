{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed point interation\n",
    "\n",
    "In numerous applications, we encounter the task of solving equations of the form $$x = g(x)$$\n",
    "for a continuous function $g$. In lab 03 we saw one simple method to solve such problems: $$x_{t+1} = g(x_t)\\,.$$\n",
    "We solved two apparently similar equations $x = log(1+x)$ and $x = log(2+x)$, with showed very different convergence.\n",
    "\n",
    "## Newton steps\n",
    "\n",
    "This week's task is to adapt the iterative algorithm to use Newton-style steps. Like in lab 03, we can do this by expressing the update step as a gradient-descent update and computing its second derivative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how the two functions look over an interval $[0,2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 2, 0.0001)\n",
    "y1 = np.log(1 + x)\n",
    "y2 = np.log(2 + x)\n",
    "fig = plt.figure()\n",
    "plt.plot(x, x, label='x')\n",
    "plt.plot(x, y1, label='$\\log(1 + x)$')\n",
    "plt.plot(x, y2, label='$\\log(2 + x)$')\n",
    "plt.grid(linestyle=':')\n",
    "plt.axhline(0, color='black')\n",
    "plt.axvline(0, color='black')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `fixed_point_newton` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_point_newton(initial_x, max_iters, objective, objective_grad):\n",
    "    \"\"\"Compute the fixed point.\"\"\"\n",
    "    # Define parameters to store x and objective func. values\n",
    "    xs = []\n",
    "    errors = []\n",
    "    x = initial_x\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute objective and error\n",
    "        obj = objective(x)\n",
    "        error = np.abs(x - obj)\n",
    "        # store x and error\n",
    "        xs.append(x)\n",
    "        errors.append(error)\n",
    "        \n",
    "        ########################\n",
    "        # @TODO Insert your code here\n",
    "        # UPDATE x with a Newton step\n",
    "        ########################\n",
    "        \n",
    "        # print the current error\n",
    "        if n_iter % 10 == 0: \n",
    "            print(\"Fixed point: iteration ={i}, x = {x:.2e}, error={err:.2e}\".format(i=n_iter, x=x, err=error))\n",
    "    return errors, xs\n",
    "\n",
    "def fixed_point(initial_x, max_iters, objective):\n",
    "    \"\"\"Compute the fixed point.\"\"\"\n",
    "    # Define parameters to store x and objective func. values\n",
    "    xs = []\n",
    "    errors = []\n",
    "    x = initial_x\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute objective and error\n",
    "        obj = objective(x)\n",
    "        error = np.abs(x - obj)\n",
    "        # store x and error\n",
    "        xs.append(x)\n",
    "        errors.append(error)\n",
    "        # update x \n",
    "        x = obj\n",
    "        # print the current error\n",
    "        if n_iter % 10 == 0: \n",
    "            print(\"Fixed point: iteration ={i}, x = {x:.2e}, error={err:.2e}\".format(i=n_iter, x=x, err=error))\n",
    "    return errors, xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the implementations and compare it to the original algorithm from lab 03:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "\n",
    "# Initialization\n",
    "initial_x = 1\n",
    "\n",
    "# Run fixed point.\n",
    "errors_func1, xs_func1 = fixed_point(\n",
    "    initial_x, \n",
    "    max_iters, \n",
    "    lambda x: np.log(1 + x)\n",
    ")\n",
    "\n",
    "errors_func1_newton, xs_func1_newton = fixed_point_newton(\n",
    "    initial_x, \n",
    "    max_iters, \n",
    "    lambda x: np.log(1 + x), \n",
    "    lambda x: 1./(1. + x)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your implementation on the second function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "\n",
    "# Initialization\n",
    "initial_x = 1\n",
    "\n",
    "# Run fixed point.\n",
    "errors_func2, xs_func2 = fixed_point(\n",
    "    initial_x, \n",
    "    max_iters, \n",
    "    lambda x: np.log(2 + x)\n",
    ")\n",
    "\n",
    "errors_func2_newton, xs_func2_newton = fixed_point_newton(\n",
    "    initial_x, \n",
    "    max_iters, \n",
    "    lambda x: np.log(2 + x), \n",
    "    lambda x: 1./(2. + x)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting error values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.semilogy()\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Value of Error')\n",
    "#plt.yscale(\"log\")\n",
    "plt.plot(range(len(errors_func1)), errors_func1, label='$log(1 + x)$')\n",
    "plt.plot(range(len(errors_func2)), errors_func2, label='$log(2 + x)$')\n",
    "plt.plot(range(len(errors_func1_newton)), errors_func1_newton, label='$log(1 + x)$ (Newton)')\n",
    "plt.plot(range(len(errors_func2_newton)), errors_func2_newton, label='$log(2 + x)$ (Newton)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe about the rates of convergence of the two methods? Can you explain this difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {
    "d2b2c3aea192430e81437f33ba0b0e69": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e4a6a7a70ccd42ddb112989c04f2ed3f": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
